name: WireGuard Speedtest

on:
  workflow_dispatch:
  schedule:
    - cron: '*/30 * * * *'  # –∫–∞–∂–¥—ã–µ 30 –º–∏–Ω—É—Ç

# –Ω—É–∂–Ω–æ, —á—Ç–æ–±—ã –ø—É—à–∏—Ç—å –≤ gh-pages —Ç–æ–∫–µ–Ω–æ–º GITHUB_TOKEN
permissions:
  contents: write

jobs:
  fetch_servers:
    runs-on: ubuntu-latest
    env:
      API_BASE_URL: ${{ secrets.API_BASE_URL }}
      MASTER_XOR_SECRET: ${{ secrets.MASTER_XOR_SECRET }}
    outputs:
      server_ids: ${{ steps.fetch.outputs.server_ids }}
    steps:
      - name: Install minimal deps
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y --no-install-recommends curl python3

      - name: Fetch server list & decode
        id: fetch
        shell: bash
        run: |
          set -euo pipefail
          python3 <<'PY'
          import os, sys, time, base64, hmac, hashlib, json, urllib.request

          BASE   = (os.getenv("API_BASE_URL") or "").rstrip("/")
          MASTER = os.getenv("MASTER_XOR_SECRET") or ""
          URL    = BASE + "/servers"
          TOUT, RET = 10, 3

          def k(m,n):  return hmac.new(m,n,hashlib.sha256).digest()
          def xo(d,kk): return bytes([b ^ kk[i%len(kk)] for i,b in enumerate(d)])

          last=None
          for _ in range(RET):
              try:
                  with urllib.request.urlopen(URL, timeout=TOUT) as r:
                      hdr=dict(r.getheaders()); body=r.read()
                  break
              except Exception as e:
                  last=e; time.sleep(2)
          else:
              print(f"::error ::Servers API not reachable: {last}"); sys.exit(1)

          xenc = hdr.get("X-Encrypted") or hdr.get("x-encrypted")
          nonce= hdr.get("X-Nonce")     or hdr.get("x-nonce")
          plain= body
          if xenc=="1" and nonce:
              if not MASTER: print("::error ::MASTER_XOR_SECRET missing"); sys.exit(1)
              plain = xo(base64.b64decode(body), k(MASTER.encode(), base64.b64decode(nonce)))

          try:
              data = json.loads(plain.decode("utf-8","ignore"))
          except Exception:
              print("::error ::Servers API returned non-JSON"); print(plain[:300]); sys.exit(1)

          print("::group::–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–µ—Ä–≤–µ—Ä–æ–≤")
          print(json.dumps(data, ensure_ascii=False, indent=2))
          print("::endgroup::")

          if not isinstance(data, list) or not data:
              print("::error ::Empty/invalid server list"); sys.exit(1)

          ids = [s.get("serverId") for s in data if s.get("serverId")]
          if not ids:
              print("::error ::No serverId found"); sys.exit(1)

          with open(os.environ["GITHUB_OUTPUT"], "a") as gh:
              gh.write(f"server_ids={json.dumps(ids)}\n")
          PY

  speedtest:
    needs: fetch_servers
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        server_id: ${{ fromJson(needs.fetch_servers.outputs.server_ids) }}
    env:
      API_BASE_URL: ${{ secrets.API_BASE_URL }}
      MASTER_XOR_SECRET: ${{ secrets.MASTER_XOR_SECRET }}

    steps:
      - name: Install WG & tools (once)
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y --no-install-recommends \
            wireguard curl jq iputils-ping iputils-tracepath

      - name: Install Ookla speedtest (static tarball, fast)
        shell: bash
        run: |
          set -euo pipefail
          if ! command -v speedtest >/dev/null 2>&1; then
            ARCH="$(uname -m)"
            case "$ARCH" in
              x86_64) SUF="x86_64" ;;
              aarch64|arm64) SUF="aarch64" ;;
              *) SUF="x86_64" ;;
            esac
            URL="https://install.speedtest.net/app/cli/ookla-speedtest-1.2.0-linux-${SUF}.tgz"
            TMP="$(mktemp -d)"
            curl -fsSL "$URL" -o "$TMP/s.tgz"
            tar -xzf "$TMP/s.tgz" -C "$TMP"
            sudo mv "$TMP/speedtest" /usr/local/bin/speedtest
            sudo chmod +x /usr/local/bin/speedtest
            rm -rf "$TMP"
          fi
          speedtest --version || true

      - name: Write helpers.py
        shell: bash
        run: |
          cat > helpers.py <<'PY'
          import json, re, subprocess
          NAME2CC = {
            "United States":"US","USA":"US",
            "United Kingdom":"GB","Great Britain":"GB","UK":"GB",
            "Germany":"DE","Netherlands":"NL","Sweden":"SE","Japan":"JP",
            "France":"FR","Canada":"CA","Italy":"IT","Spain":"ES",
            "Poland":"PL","Finland":"FI","Norway":"NO","Denmark":"DK",
          }
          def to_cc(name:str)->str:
            if not name: return ""
            n=name.strip()
            if n in NAME2CC: return NAME2CC[n]
            up = re.sub(r'[^A-Z ]','', n.upper()).split()
            return ''.join(w[0] for w in up)[:2] if up else ""

          def parse_ookla(raw:str):
            j = json.loads(raw)
            def mbps(sec):
              try: return round((sec.get("bandwidth",0)*8)/1e6, 2)
              except: return None
            def mega_bytes(sec):
              try: return round((sec.get("bytes",0))/1e6, 0)
              except: return None
            ping = None
            try: ping = round(float((j.get("ping") or {}).get("latency")), 2)
            except: pass
            jitter = None
            try: jitter = round(float((j.get("ping") or {}).get("jitter")), 2)
            except: pass
            pl = (j.get("packetLoss") if isinstance(j.get("packetLoss"), (int,float)) else None)
            geo_country = ((j.get("server") or {}).get("country")) or ""
            return {
              "ping_ms": ping,
              "jitter_ms": jitter,
              "packet_loss_pct": (round(float(pl),2) if pl is not None else None),
              "download_Mbps": mbps(j.get("download",{})),
              "upload_Mbps":   mbps(j.get("upload",{})),
              "download_MB":   mega_bytes(j.get("download",{})),
              "upload_MB":     mega_bytes(j.get("upload",{})),
              "server": {
                "host": (j.get("server") or {}).get("host"),
                "name": (j.get("server") or {}).get("name"),
                "country": geo_country,
                "cc": to_cc(geo_country),
                "sponsor": (j.get("server") or {}).get("sponsor"),
              }
            }

          def light_ping_stats(target="1.1.1.1", count=20):
            try:
              r = subprocess.run(["ping","-c",str(count),target], capture_output=True, text=True, check=True)
              out = r.stdout
            except Exception:
              return None, None
            m = re.search(r'(\d+(?:\.\d+)?)% packet loss', out)
            loss = float(m.group(1)) if m else None
            m = re.search(r'=\s*([\d\.]+)/([\d\.]+)/([\d\.]+)/([\d\.]+)\s*ms', out)
            mdev = float(m.group(4)) if m else None
            return loss, mdev

          def quick_mtu(target="1.1.1.1"):
            try:
              r = subprocess.run(["tracepath","-n","-m","6",target], capture_output=True, text=True, check=True)
              out = r.stdout
            except Exception:
              return None
            m = re.search(r'\bpmtu\s+(\d+)', out)
            return int(m.group(1)) if m else None
          PY

      - name: Novpn (no VPN)
        shell: bash
        env:
          SID: ${{ matrix.server_id }}
        run: |
          set -euo pipefail
          OUT="$(mktemp)"
          speedtest --accept-license --accept-gdpr >/dev/null 2>&1 || true
          speedtest -f json --progress=no >"$OUT"
          python3 - "$OUT" <<'PY'
          import json, os, sys
          import helpers
          sid=os.getenv("SID","?")
          raw = open(sys.argv[1]).read()
          data = helpers.parse_ookla(raw)
          loss, mdev = helpers.light_ping_stats()
          pmtu = helpers.quick_mtu()
          result = {
            "kind": "novpn",
            "server_id": sid,
            **data,
            "mtu": {"pmtu": pmtu},
          }
          if loss is not None: result["packet_loss_pct"]=loss
          if mdev is not None: result["jitter_ms"]=mdev
          print("::group::Novpn result")
          print(json.dumps(result, ensure_ascii=False, indent=2))
          print("::endgroup::")
          open(f"novpn-{sid}.json","w").write(json.dumps(result, ensure_ascii=False))
          PY

      - name: Write fetch_wgconf.py
        shell: bash
        run: |
          cat > fetch_wgconf.py <<'PY'
          import os, sys, time, base64, hmac, hashlib, json, urllib.request
          import subprocess, re

          BASE   = (os.getenv("API_BASE_URL") or "").rstrip("/")
          MASTER = os.getenv("MASTER_XOR_SECRET") or ""
          SID    = os.getenv("SID","")
          ISG    = os.getenv("IS_GRAND","true")
          URL    = f"{BASE}/get-config?server_id={SID}&is_grand={ISG}"
          TOUT, RET = 10, 3

          def k(m,n):  return hmac.new(m,n,hashlib.sha256).digest()
          def xo(d,kk): return bytes([b ^ kk[i%len(kk)] for i,b in enumerate(d)])

          last=None
          for _ in range(RET):
            try:
              with urllib.request.urlopen(URL, timeout=TOUT) as r:
                hdr=dict(r.getheaders()); body=r.read()
              break
            except Exception as e:
              last=e; time.sleep(2)
          else:
            print(f"::error ::Config API unreachable: {last}"); sys.exit(1)

          xenc = hdr.get("X-Encrypted") or hdr.get("x-encrypted")
          nonce= hdr.get("X-Nonce")     or hdr.get("x-nonce")
          text = body.decode("utf-8","ignore")
          if xenc=="1" and nonce:
            if not MASTER: print("::error ::MASTER_XOR_SECRET empty"); sys.exit(1)
            text = xo(base64.b64decode(body), k(MASTER.encode(), base64.b64decode(nonce))).decode("utf-8","ignore")

          try:
            j=json.loads(text)
          except Exception:
            print("::error ::Config not JSON"); print(text[:400]); sys.exit(1)

          need=["private_key","address","server_ip","server_port","server_public_key"]
          if any(k not in j or not j[k] for k in need):
            print("::error ::Config JSON missing keys"); sys.exit(1)

          wg = "\n".join([
            "[Interface]",
            "PrivateKey = "+j["private_key"],
            "Address = "+j["address"],
            "DNS = 1.1.1.1",
            "",
            "[Peer]",
            "PublicKey = "+j["server_public_key"],
            "AllowedIPs = 0.0.0.0/0, ::/0",
            "Endpoint = "+j["server_ip"]+":"+str(j["server_port"]),
            "PersistentKeepalive = 25",
            ""
          ])
          open("wg0.conf","w").write(wg)
          subprocess.check_call(["sudo","mkdir","-p","/etc/wireguard"])
          subprocess.check_call(["sudo","mv","wg0.conf","/etc/wireguard/wg0.conf"])
          subprocess.check_call(["sudo","chmod","600","/etc/wireguard/wg0.conf"])
          masked = re.sub(r'(?m)^(PrivateKey\s*=\s*).+$', r'\\1***', wg)
          print(f"::group::wg0.conf (masked) ‚Äî is_grand={ISG}")
          print(masked)
          print("::endgroup::")
          PY

      - name: Fetch config (grand) & install
        shell: bash
        env:
          SID: ${{ matrix.server_id }}
          IS_GRAND: "true"
        run: |
          set -euo pipefail
          python3 fetch_wgconf.py

      - name: Connect VPN (grand)
        shell: bash
        run: |
          set -euo pipefail
          sudo wg-quick up wg0
          sudo wg show

      - name: Speedtest (grand)
        shell: bash
        env:
          SID: ${{ matrix.server_id }}
          PLAN: "grand"
        run: |
          set -euo pipefail
          OUT="$(mktemp)"
          speedtest -f json --progress=no --accept-license --accept-gdpr >"$OUT"
          python3 - "$OUT" <<'PY'
          import json, os, sys
          import helpers
          sid=os.getenv("SID","?"); plan=os.getenv("PLAN","grand")
          raw=open(sys.argv[1]).read()
          data=helpers.parse_ookla(raw)
          loss,mdev=helpers.light_ping_stats()
          pmtu=helpers.quick_mtu()
          res={"kind":plan,"server_id":sid, **data, "mtu":{"pmtu":pmtu}}
          if loss is not None: res["packet_loss_pct"]=loss
          if mdev is not None: res["jitter_ms"]=mdev
          print("::group::Speedtest result (grand)")
          print(json.dumps(res, ensure_ascii=False, indent=2))
          print("::endgroup::")
          open(f"result-{sid}-{plan}.json","w").write(json.dumps(res, ensure_ascii=False))
          PY

      - name: Disconnect VPN (grand)
        if: always()
        shell: bash
        run: sudo wg-quick down wg0 || true

      - name: Fetch config (basic) & install
        shell: bash
        env:
          SID: ${{ matrix.server_id }}
          IS_GRAND: "false"
        run: |
          set -euo pipefail
          python3 fetch_wgconf.py

      - name: Connect VPN (basic)
        shell: bash
        run: |
          set -euo pipefail
          sudo wg-quick up wg0
          sudo wg show

      - name: Speedtest (basic)
        shell: bash
        env:
          SID: ${{ matrix.server_id }}
          PLAN: "basic"
        run: |
          set -euo pipefail
          OUT="$(mktemp)"
          speedtest -f json --progress=no --accept-license --accept-gdpr >"$OUT"
          python3 - "$OUT" <<'PY'
          import json, os, sys
          import helpers
          sid=os.getenv("SID","?"); plan=os.getenv("PLAN","basic")
          raw=open(sys.argv[1]).read()
          data=helpers.parse_ookla(raw)
          loss,mdev=helpers.light_ping_stats()
          pmtu=helpers.quick_mtu()
          res={"kind":plan,"server_id":sid, **data, "mtu":{"pmtu":pmtu}}
          if loss is not None: res["packet_loss_pct"]=loss
          if mdev is not None: res["jitter_ms"]=mdev
          print("::group::Speedtest result (basic)")
          print(json.dumps(res, ensure_ascii=False, indent=2))
          print("::endgroup::")
          open(f"result-{sid}-{plan}.json","w").write(json.dumps(res, ensure_ascii=False))
          PY

      - name: Disconnect VPN (basic)
        if: always()
        shell: bash
        run: sudo wg-quick down wg0 || true

      - name: Upload artifacts for ${{ matrix.server_id }}
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: speedtests-${{ matrix.server_id }}
          path: |
            novpn-${{ matrix.server_id }}.json
            result-${{ matrix.server_id }}-grand.json
            result-${{ matrix.server_id }}-basic.json

  notify:
    needs: [fetch_servers, speedtest]
    runs-on: ubuntu-latest
    if: always()
    env:
      TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
      TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
    steps:
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: results

      - name: Build summary (compact + CC + thresholds)
        shell: bash
        run: |
          set -euo pipefail
          python3 <<'PY'
          import glob, json, os, re

          LOSS_BAD   = 1.0
          JITTER_BAD = 10.0
          GRAND_DL_RED = 100.0
          BASIC_DL_RED = 5.0

          NAME2CC = {
            "United States":"US","USA":"US",
            "United Kingdom":"GB","Great Britain":"GB","UK":"GB",
            "Germany":"DE","Netherlands":"NL","Sweden":"SE","Japan":"JP",
            "France":"FR","Canada":"CA","Italy":"IT","Spain":"ES",
            "Poland":"PL","Finland":"FI","Norway":"NO","Denmark":"DK",
          }
          def to_cc(name:str)->str:
            if not name: return ""
            n=name.strip()
            if n in NAME2CC: return NAME2CC[n]
            up = re.sub(r'[^A-Z ]','', n.upper()).split()
            return ''.join(w[0] for w in up)[:2] if up else ""

          def sid_from_name(p):
            b=os.path.basename(p)
            if b.endswith('.json'): b=b[:-5]
            m=re.match(r'novpn-(.+)$',b)
            if m: return m.group(1)
            m=re.match(r'result-(.+?)-(grand|basic)$',b)
            if m: return m.group(1)
            return None

          files = sorted(glob.glob('results/**/*.json', recursive=True))
          if not files:
            msg="‚ö†Ô∏è WG Speedtest: no results found."
            open("summary.txt","w").write(msg); print(msg); raise SystemExit(0)

          novpn, grand, basic = {}, {}, {}
          def take(dst, sid, path, obj):
            cur = dst.get(sid)
            if (not cur) or (os.path.getmtime(path) > os.path.getmtime(cur[0])):
              dst[sid] = (path, obj)

          for p in files:
            try:
              j = json.load(open(p))
            except Exception:
              continue
            sid = j.get("server_id") or sid_from_name(p)
            if not sid: 
              continue
            kind = (j.get("kind") or "").lower()
            if   kind == "novpn": take(novpn, sid, p, j)
            elif kind == "grand": take(grand, sid, p, j)
            elif kind == "basic": take(basic, sid, p, j)

          sids = sorted(set(novpn)|set(grand)|set(basic))
          if not sids:
            msg="‚ö†Ô∏è WG Speedtest: no results found."
            open("summary.txt","w").write(msg); print(msg); raise SystemExit(0)

          def brief(d):
            if not d: return ("n/a ‚ùå", None, None, None)
            j = d[1]
            p = j.get("ping_ms")
            dl = j.get("download_Mbps")
            ul = j.get("upload_Mbps")
            if dl is None and ul is None and p is None:
              return ("n/a ‚ùå", None, j, p)
            return (f"ping {p} ms, ‚Üì {dl} Mb/s, ‚Üë {ul} Mb/s", dl, j, p)

          def geo_cc(j):
            try:
              return to_cc(((j or {}).get("server") or {}).get("country") or "")
            except: return ""

          def ints(x): 
            try: return int(x or 0)
            except: return 0

          speeds = ["üìà WG Speedtest ‚Äî novpn vs grand vs basic", "", "SPEEDS:"]
          details = ["", "DETAILS:"]

          for i, sid in enumerate(sids, 1):
            b = novpn.get(sid)
            g = grand.get(sid)
            s = basic.get(sid)

            b_txt, b_dl, b_j, b_ping = brief(b)
            g_txt, g_dl, g_j, g_ping = brief(g)
            s_txt, s_dl, s_j, s_ping = brief(s)

            if g_dl is not None and g_dl < GRAND_DL_RED: g_txt += " ‚ùå"
            if s_dl is not None and s_dl < BASIC_DL_RED: s_txt += " ‚ùå"
            if g_ping is not None and g_ping > 200: g_txt += " ‚ùå"
            if s_ping is not None and s_ping > 200: s_txt += " ‚ùå"

            speeds.append(
              f"{i}) '{sid}':\n"
              f"  novpn : {b_txt}\n"
              f"  grand : {g_txt}\n"
              f"  basic  : {s_txt}"
            )

            def diag(j):
              if not j: 
                return ("n/a","‚Äî","n/a","n/a","0/0")
              cc = geo_cc(j)
              pmtu = (j.get("mtu") or {}).get("pmtu")
              loss = j.get("packet_loss_pct")
              jit  = j.get("jitter_ms")
              loss_ok = (loss is None) or (loss <= 1.0)
              jit_ok  = (jit  is None) or (jit  <= 10.0)
              loss_s = "n/a" if loss is None else f"{loss}%"
              jit_s  = "n/a" if jit  is None else f"{jit}ms"
              mtu_s  = str(pmtu) if pmtu else "‚Äî"
              def ints(v): 
                try: return int(v or 0)
                except: return 0
              traf   = f"{ints(j.get('download_MB'))}/{ints(j.get('upload_MB'))}"
              mtu_s  = f"{mtu_s}{' ‚úÖ' if (pmtu or 0)>=1400 else ' ‚ùå'}"
              loss_s = f"{loss_s}{' ‚úÖ' if loss_ok else ' ‚ùå'}"
              jit_s  = f"{jit_s}{' ‚úÖ' if jit_ok  else ' ‚ùå'}"
              return (cc, mtu_s, loss_s, jit_s, traf)

            b_cc,b_mtu,b_loss,b_jit,b_tr = diag(b_j)
            g_cc,g_mtu,g_loss,g_jit,g_tr = diag(g_j)
            s_cc,s_mtu,s_loss,s_jit,s_tr = diag(s_j)

            details.append(
              f"{i}) {sid}: "
              f"geo {b_cc} | {g_cc} | {s_cc}; "
              f"MTU: {b_mtu} | {g_mtu} | {s_mtu}; "
              f"loss: {b_loss} | {g_loss} | {s_loss}; "
              f"jitter: {b_jit} | {g_jit} | {s_jit}; "
              f"MB dw/up: {b_tr} | {g_tr} | {s_tr}"
            )

          msg = "\n".join(speeds + details)
          open("summary.txt","w").write(msg)
          print(msg)
          PY

      - name: Send Telegram
        shell: bash
        run: |
          set -euo pipefail
          BOT="${{ env.TELEGRAM_BOT_TOKEN }}"
          CHAT="${{ env.TELEGRAM_CHAT_ID }}"
          if [[ -z "$BOT" || -z "$CHAT" ]]; then
            echo "Telegram secrets missing, skipping."
            exit 0
          fi
          MSG="$(cat summary.txt)"
          curl -s "https://api.telegram.org/bot${BOT}/sendMessage" \
            -d "chat_id=${CHAT}" \
            --data-urlencode "text=${MSG}" >/dev/null || true

  publish_pages:
    needs: [fetch_servers, speedtest]
    if: always()     # –ø—É–±–ª–∏–∫—É–µ–º —Å–∞–π—Ç –¥–∞–∂–µ –ø—Ä–∏ —á–∞—Å—Ç–∏—á–Ω—ã—Ö —Ñ–µ–π–ª–∞—Ö
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo (for docs/index.html)
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Download artifacts (merge all)
        uses: actions/download-artifact@v4
        with:
          pattern: speedtests-*
          merge-multiple: true
          path: results

      - name: Try fetch previous stats (from gh-pages)
        shell: bash
        env:
          RAW_URL: "https://raw.githubusercontent.com/${{ github.repository }}/gh-pages/data/stats.json"
        run: |
          set -euo pipefail
          curl -fsSL "$RAW_URL" -o prev-stats.json || echo "{}" > prev-stats.json

      - name: Build site (index.html + data/stats.json; merge history)
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p site/data
          cp -f docs/index.html site/index.html
          touch site/.nojekyll

          python3 <<'PY'
          import glob, json, os, re, time
          KEEP_PER_PROFILE = 500  # –ª–∏–º–∏—Ç –∏—Å—Ç–æ—Ä–∏–∏ –Ω–∞ (sid, profile)

          def sid_from_name(p):
              b=os.path.basename(p)
              if b.endswith('.json'): b=b[:-5]
              m=re.match(r'novpn-(.+)$',b)
              if m: return m.group(1)
              m=re.match(r'result-(.+?)-(grand|basic)$',b)
              if m: return m.group(1)
              return None

          def load_json_safe(path, default=None):
              try:
                  with open(path,'r',encoding='utf-8') as f:
                      return json.load(f)
              except Exception:
                  return default

          # ----- load prev points (support both formats) -----
          prev = load_json_safe('prev-stats.json', {}) or {}
          prev_points = []
          if isinstance(prev, dict):
              if isinstance(prev.get('points'), list):
                  prev_points = prev['points']
              else:
                  # –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç (–ø–æ sid) ‚Üí —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—å –≤ points
                  for sid, obj in prev.items():
                      if not isinstance(obj, dict) or sid in ('last','_generated_at'):
                          continue
                      ts = obj.get('timestamps') or []
                      for prof in ('novpn','grand','basic'):
                          prof_obj = (obj.get(prof) or {})
                          for i, t in enumerate(ts):
                              def gv(k):
                                  arr = prof_obj.get(k) or []
                                  return arr[i] if i < len(arr) else None
                              if gv('download') is None and gv('upload') is None and gv('ping') is None:
                                  continue
                              prev_points.append({
                                  "ts": t, "sid": sid, "profile": prof,
                                  "ping": gv('ping'), "down": gv('download'), "up": gv('upload'),
                                  "loss": None, "jitter": None, "pmtu": None, "geo": None
                              })

          # ----- collect new run points -----
          files = sorted(glob.glob('results/**/*.json', recursive=True))
          run_points=[]
          for p in files:
              j = load_json_safe(p)
              if not isinstance(j, dict): 
                  continue
              sid = j.get("server_id") or sid_from_name(p)
              prof = (j.get("kind") or "").lower()
              if not sid or prof not in ("novpn","grand","basic"):
                  continue
              t = int(os.path.getmtime(p))*1000
              run_points.append({
                  "ts": t,
                  "sid": sid,
                  "profile": prof,
                  "ping": j.get("ping_ms"),
                  "down": j.get("download_Mbps"),
                  "up": j.get("upload_Mbps"),
                  "loss": j.get("packet_loss_pct"),
                  "jitter": j.get("jitter_ms"),
                  "pmtu": (j.get("mtu") or {}).get("pmtu"),
                  "geo": ((j.get("server") or {}).get("cc") or ((j.get("server") or {}).get("country")))
              })

          # ----- merge & dedup -----
          all_points = prev_points + run_points
          all_points.sort(key=lambda x:(x['sid'], x['profile'], int(x['ts'])))
          dedup=[]
          seen=set()
          for p in all_points:
              k=(p['sid'], p['profile'], int(p['ts']))
              if k in seen: 
                  continue
              seen.add(k)
              dedup.append(p)

          # –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –ø–æ (sid, profile)
          from collections import defaultdict
          buckets=defaultdict(list)
          for p in dedup:
              buckets[(p['sid'], p['profile'])].append(p)
          limited=[]
          for (sid,prof), arr in buckets.items():
              arr.sort(key=lambda x:x['ts'])
              if len(arr)>KEEP_PER_PROFILE:
                  arr = arr[-KEEP_PER_PROFILE:]
              limited.extend(arr)

          out = {"points": limited, "generated_at": int(time.time()*1000)}
          os.makedirs("site/data", exist_ok=True)
          with open("site/data/stats.json","w",encoding="utf-8") as f:
              json.dump(out, f, ensure_ascii=False)
          # –Ω–∞ –≤—Å—è–∫–∏–π ‚Äî –¥—É–±–ª–∏—Ä—É–µ–º –≤ –∫–æ—Ä–µ–Ω—å, –µ—Å–ª–∏ –≤–¥—Ä—É–≥ –∫—Ç–æ-—Ç–æ –≥—Ä—É–∑–∏—Ç —Å—Ç–∞—Ä—ã–º –ø—É—Ç—ë–º
          with open("site/stats.json","w",encoding="utf-8") as f:
              json.dump(out, f, ensure_ascii=False)
          print("Wrote site/data/stats.json; points:", len(limited))
          PY

          ls -la site site/data

      - name: Publish to gh-pages (single orphan commit)
        shell: bash
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          cd site
          git init -b gh-pages
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add .
          git commit -m "Publish dashboard"
          git remote add origin "https://x-access-token:${GH_TOKEN}@github.com/${GITHUB_REPOSITORY}.git"
          git push --force origin gh-pages